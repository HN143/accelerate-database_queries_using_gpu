{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "average_path_1 = \"tpc-h/result_log/result_log_2GB/time_1/average_query_sys_params.csv\"\n",
    "average_path_2 = \"tpc-h/result_log/result_log_2GB/time_2/average_query_sys_params.csv\"\n",
    "average_path_3 = \"tpc-h/result_log/result_log_2GB/time_3/average_query_sys_params.csv\"\n",
    "\n",
    "worst_path_1 = \"tpc-h/result_log/result_log_2GB/time_1/worst_query_sys_params.csv\"\n",
    "worst_path_2 = \"tpc-h/result_log/result_log_2GB/time_2/worst_query_sys_params.csv\"\n",
    "worst_path_3 = \"tpc-h/result_log/result_log_2GB/time_3/worst_query_sys_params.csv\"\n",
    "\n",
    "worst_output_path = \"tpc-h/result_log/result_log_2GB/worst_query_sys_params.csv\"\n",
    "average_output_path = \"tpc-h/result_log/result_log_2GB/average_query_sys_params.csv\"\n",
    "# Đường dẫn đến 3 file CSV\n",
    "average_paths = [\n",
    "    average_path_1,average_path_2,average_path_3\n",
    "]\n",
    "worst_paths = [\n",
    "    worst_path_1,worst_path_2,worst_path_3\n",
    "]\n",
    "# Các cột cần thiết\n",
    "columns_to_use = [\n",
    "    \"query_id\",\"cpu_used(%)\",\"ram_used(gb)\",\"time(ms)\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query_metrics(paths, columns_to_use, output_path):\n",
    "    # Read, filter, and clean data\n",
    "    dfs = [\n",
    "        pd.read_csv(path, comment='/')[columns_to_use]\n",
    "        .assign(query_id=lambda df: df['query_id'].astype(str).str.strip())  # Convert to string and strip\n",
    "        for path in paths\n",
    "    ]\n",
    "    \n",
    "    # Merge data and calculate average by query_id\n",
    "    all_data = pd.concat(dfs)\n",
    "    average_metrics = all_data.groupby('query_id', as_index=False).mean(numeric_only=True)\n",
    "    average_metrics = average_metrics.round(2)\n",
    "    \n",
    "    # Add column for sorting by number in query_id\n",
    "    average_metrics['query_number'] = average_metrics['query_id'].apply(lambda x: int(re.search(r'\\d+', x).group()))\n",
    "    \n",
    "    # Sort by query number\n",
    "    average_metrics = average_metrics.sort_values(by='query_number').drop(columns=['query_number'])\n",
    "    \n",
    "    # Write to file\n",
    "    average_metrics.to_csv(output_path, index=False)\n",
    "    \n",
    "    return average_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Process average metrics\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m average_metrics = \u001b[43mprocess_query_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43maverage_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns_to_use\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43maverage_output_path\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Process worst metrics\u001b[39;00m\n\u001b[32m      9\u001b[39m worst_metrics = process_query_metrics(\n\u001b[32m     10\u001b[39m     worst_paths,\n\u001b[32m     11\u001b[39m     columns_to_use,\n\u001b[32m     12\u001b[39m     worst_output_path\n\u001b[32m     13\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mprocess_query_metrics\u001b[39m\u001b[34m(paths, columns_to_use, output_path)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess_query_metrics\u001b[39m(paths, columns_to_use, output_path):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Read, filter, and clean data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     dfs = [\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns_to_use\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mquery_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m      4\u001b[39m            \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m paths]\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Merge data and calculate average by query_id\u001b[39;00m\n\u001b[32m      7\u001b[39m     all_data = pd.concat(dfs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:5239\u001b[39m, in \u001b[36mDataFrame.assign\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   5236\u001b[39m data = \u001b[38;5;28mself\u001b[39m.copy(deep=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   5238\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items():\n\u001b[32m-> \u001b[39m\u001b[32m5239\u001b[39m     data[k] = \u001b[43mcom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply_if_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/common.py:384\u001b[39m, in \u001b[36mapply_if_callable\u001b[39m\u001b[34m(maybe_callable, obj, **kwargs)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[33;03mEvaluate possibly callable input using obj and kwargs if it is callable,\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[33;03motherwise return as it is.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    381\u001b[39m \u001b[33;03m**kwargs\u001b[39;00m\n\u001b[32m    382\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(maybe_callable):\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmaybe_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_callable\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mprocess_query_metrics.<locals>.<lambda>\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess_query_metrics\u001b[39m(paths, columns_to_use, output_path):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Read, filter, and clean data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     dfs = [pd.read_csv(path, comment=\u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m)[columns_to_use].assign(query_id=\u001b[38;5;28;01mlambda\u001b[39;00m df: \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mquery_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstr\u001b[49m.strip()) \n\u001b[32m      4\u001b[39m            \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m paths]\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Merge data and calculate average by query_id\u001b[39;00m\n\u001b[32m      7\u001b[39m     all_data = pd.concat(dfs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/generic.py:6299\u001b[39m, in \u001b[36mNDFrame.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6292\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   6293\u001b[39m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._internal_names_set\n\u001b[32m   6294\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._metadata\n\u001b[32m   6295\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._accessors\n\u001b[32m   6296\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6297\u001b[39m ):\n\u001b[32m   6298\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[32m-> \u001b[39m\u001b[32m6299\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/accessor.py:224\u001b[39m, in \u001b[36mCachedAccessor.__get__\u001b[39m\u001b[34m(self, obj, cls)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._accessor\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m accessor_obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[32m    226\u001b[39m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[32m    227\u001b[39m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[32m    228\u001b[39m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[38;5;28mobject\u001b[39m.\u001b[34m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m._name, accessor_obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/strings/accessor.py:191\u001b[39m, in \u001b[36mStringMethods.__init__\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstring_\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28mself\u001b[39m._inferred_dtype = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m     \u001b[38;5;28mself\u001b[39m._is_categorical = \u001b[38;5;28misinstance\u001b[39m(data.dtype, CategoricalDtype)\n\u001b[32m    193\u001b[39m     \u001b[38;5;28mself\u001b[39m._is_string = \u001b[38;5;28misinstance\u001b[39m(data.dtype, StringDtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/strings/accessor.py:245\u001b[39m, in \u001b[36mStringMethods._validate\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    242\u001b[39m inferred_dtype = lib.infer_dtype(values, skipna=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan only use .str accessor with string values!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[31mAttributeError\u001b[39m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "# Process average metrics\n",
    "average_metrics = process_query_metrics(\n",
    "    average_paths, \n",
    "    columns_to_use, \n",
    "    average_output_path\n",
    ")\n",
    "\n",
    "# Process worst metrics\n",
    "worst_metrics = process_query_metrics(\n",
    "    worst_paths,\n",
    "    columns_to_use,\n",
    "    worst_output_path\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
