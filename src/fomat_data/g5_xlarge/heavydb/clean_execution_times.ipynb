{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "064af0e2",
   "metadata": {},
   "source": [
    "# TPC-DS Query Execution Time Data Cleaning\n",
    "\n",
    "This notebook cleans the query execution time data from three different runs of TPC-DS benchmark on HeavyDB. The cleaning process involves:\n",
    "1. Fixing formatting issues (e.g., query 24 with split values)\n",
    "2. Handling missing time values\n",
    "3. Ensuring consistent data formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5812e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "nums_list = [\"1\", \"5\", \"10\",\"20\", \"50\"]\n",
    "tpc_types = [\"tpc-h/\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52d7c39",
   "metadata": {},
   "source": [
    "## Define Cleaning Function\n",
    "\n",
    "This function handles the common cleaning tasks for all CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f96be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_csv_file(file_path):\n",
    "    \"\"\"Clean the query execution time CSV file.\"\"\"\n",
    "    \n",
    "    # Read the raw content of the file to handle the special case with query 24\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Fix the issue with query 24 where a value appears on a separate line\n",
    "    fixed_lines = []\n",
    "    for i, line in enumerate(lines):\n",
    "        if i > 0 and re.match(r'^\\d+$', line.strip()):\n",
    "            # This is a lone number - append it to the previous line\n",
    "            # fixed_lines[-1] = fixed_lines[-1].strip() + line.strip() + '\\n'\n",
    "            continue\n",
    "        else:\n",
    "            fixed_lines.append(line)\n",
    "    \n",
    "    # Write the fixed content to a temporary file\n",
    "    import tempfile\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, mode='w')\n",
    "    temp_file.writelines(fixed_lines)\n",
    "    temp_file.close()\n",
    "    \n",
    "    # Read the CSV with pandas\n",
    "    df = pd.read_csv(temp_file.name, sep=',', skipinitialspace=True)\n",
    "    \n",
    "    # Remove the temporary file\n",
    "    os.unlink(temp_file.name)\n",
    "    \n",
    "    # Clean column names\n",
    "    df.columns = [col.strip() for col in df.columns]\n",
    "    \n",
    "    # Convert time column to numeric, with NaN for missing values\n",
    "    df['time (ms)'] = pd.to_numeric(df['time (ms)'], errors='coerce')\n",
    "    \n",
    "    # Remove rows where time (ms) is NaN\n",
    "    df = df.dropna(subset=['time (ms)'])\n",
    "    \n",
    "    # Return only the query and time columns\n",
    "    return df[['query', 'time (ms)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60cb616",
   "metadata": {},
   "source": [
    "## Process Each File\n",
    "\n",
    "Apply the cleaning function to each input file and save the cleaned results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7d952cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning run1 data...\n",
      "Saved cleaned data to tpc-h/1gb/cleaned/run1_cleaned.csv\n",
      "Cleaning run2 data...\n",
      "Saved cleaned data to tpc-h/1gb/cleaned/run2_cleaned.csv\n",
      "Cleaning run3 data...\n",
      "Saved cleaned data to tpc-h/1gb/cleaned/run3_cleaned.csv\n",
      "\n",
      "Cleaning complete!\n",
      "Cleaning run1 data...\n",
      "Saved cleaned data to tpc-h/5gb/cleaned/run1_cleaned.csv\n",
      "Cleaning run2 data...\n",
      "Saved cleaned data to tpc-h/5gb/cleaned/run2_cleaned.csv\n",
      "Cleaning run3 data...\n",
      "Saved cleaned data to tpc-h/5gb/cleaned/run3_cleaned.csv\n",
      "\n",
      "Cleaning complete!\n",
      "Cleaning run1 data...\n",
      "Saved cleaned data to tpc-h/10gb/cleaned/run1_cleaned.csv\n",
      "Cleaning run2 data...\n",
      "Saved cleaned data to tpc-h/10gb/cleaned/run2_cleaned.csv\n",
      "Cleaning run3 data...\n",
      "Saved cleaned data to tpc-h/10gb/cleaned/run3_cleaned.csv\n",
      "\n",
      "Cleaning complete!\n",
      "Cleaning run1 data...\n",
      "Saved cleaned data to tpc-h/20gb/cleaned/run1_cleaned.csv\n",
      "Cleaning run2 data...\n",
      "Saved cleaned data to tpc-h/20gb/cleaned/run2_cleaned.csv\n",
      "Cleaning run3 data...\n",
      "Saved cleaned data to tpc-h/20gb/cleaned/run3_cleaned.csv\n",
      "\n",
      "Cleaning complete!\n",
      "Cleaning run1 data...\n",
      "Saved cleaned data to tpc-h/50gb/cleaned/run1_cleaned.csv\n",
      "Cleaning run2 data...\n",
      "Saved cleaned data to tpc-h/50gb/cleaned/run2_cleaned.csv\n",
      "Cleaning run3 data...\n",
      "Saved cleaned data to tpc-h/50gb/cleaned/run3_cleaned.csv\n",
      "\n",
      "Cleaning complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for tpc_type in tpc_types:\n",
    "    for num in nums_list:\n",
    "        base_dir = tpc_type+num+'gb/'\n",
    "        input_files = {\n",
    "            'run1': os.path.join(base_dir, 'run1/query'+num+'_execution_times.csv'),\n",
    "            'run2': os.path.join(base_dir, 'run2/query'+num+'_execution_times.csv'),\n",
    "            'run3': os.path.join(base_dir, 'run3/query'+num+'_execution_times.csv')\n",
    "        }\n",
    "\n",
    "        # Create output directory for cleaned data\n",
    "        output_dir = os.path.join(base_dir, 'cleaned')\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        output_files = {\n",
    "            'run1': os.path.join(output_dir, 'run1_cleaned.csv'),\n",
    "            'run2': os.path.join(output_dir, 'run2_cleaned.csv'),\n",
    "            'run3': os.path.join(output_dir, 'run3_cleaned.csv')\n",
    "        }\n",
    "\n",
    "\n",
    "        # Process each file and save the cleaned version\n",
    "        cleaned_dfs = {}\n",
    "\n",
    "        for run, file_path in input_files.items():\n",
    "            print(f\"Cleaning {run} data...\")\n",
    "            df = clean_csv_file(file_path)\n",
    "            cleaned_dfs[run] = df\n",
    "            \n",
    "            # Save the cleaned file\n",
    "            df.to_csv(output_files[run], index=False)\n",
    "            print(f\"Saved cleaned data to {output_files[run]}\")\n",
    "\n",
    "        print(\"\\nCleaning complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
